{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization of model parameters was done previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from scipy.stats import norm, skew\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train_clean.csv\")\n",
    "test = pd.read_csv(\"../data/test_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the 'Id' column\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "\n",
    "#Now drop the 'Id' colum since it's unnecessary for the prediction process.\n",
    "train.drop(\"Id\", axis = 1, inplace = True)\n",
    "test.drop(\"Id\", axis = 1, inplace = True)\n",
    "\n",
    "ytrain = train[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine data\n",
    "train.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "test.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "train.drop(['SalePrice'], axis=1, inplace=True)\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSSubClass should be string\n",
    "all_data[\"MSSubClass\"] = all_data[\"MSSubClass\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addlogs(res, ls):\n",
    "    m = res.shape[1]\n",
    "    for l in ls:\n",
    "        res = res.assign(newcol=pd.Series(np.log(1.01+res[l])).values)   \n",
    "        res.columns.values[m] = l + '_log'\n",
    "        m += 1\n",
    "    return res\n",
    "\n",
    "loglist = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF',\n",
    "                 'TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea',\n",
    "                 'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr',\n",
    "                 'TotRmsAbvGrd','Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF',\n",
    "                 'EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','YearRemodAdd','TotalSF']\n",
    "\n",
    "all_data = addlogs(all_data, loglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSquared(res, ls):\n",
    "    m = res.shape[1]\n",
    "    for l in ls:\n",
    "        res = res.assign(newcol=pd.Series(res[l]*res[l]).values)   \n",
    "        res.columns.values[m] = l + '_sq'\n",
    "        m += 1\n",
    "    return res \n",
    "\n",
    "sqpredlist = ['YearRemodAdd', 'LotFrontage_log', \n",
    "              'TotalBsmtSF_log', '1stFlrSF_log', '2ndFlrSF_log', 'GrLivArea_log',\n",
    "              'GarageCars_log', 'GarageArea_log']\n",
    "all_data = addSquared(all_data, sqpredlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all continuous variables\n",
    "all_non_object = all_data.dtypes[all_data.dtypes != \"object\"].index.tolist()\n",
    "# do not consider Year,Month and Qual as continuous\n",
    "year_month = [\"YearBuilt\", \"YearRemodAdd\",\"GarageYrBlt\",\"MoSold\",\"YrSold\",\n",
    "              \"OverallQual\",\"OverallCond\"]\n",
    "# numeric_features\n",
    "numeric_features = list(set(all_non_object)-set(year_month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "# Check the skew of all numerical features\n",
    "skewed_feats = all_data[numeric_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "\n",
    "# check skewness of numerical variables\n",
    "skewness = skewness[abs(skewness.Skew)>0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_dict = {\"None\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5}\n",
    "all_data[\"ExterQual\"] = all_data[\"ExterQual\"].map(qual_dict).astype(int)\n",
    "all_data[\"ExterCond\"] = all_data[\"ExterCond\"].map(qual_dict).astype(int)\n",
    "all_data[\"BsmtQual\"] = all_data[\"BsmtQual\"].map(qual_dict).astype(int)\n",
    "all_data[\"BsmtCond\"] = all_data[\"BsmtCond\"].map(qual_dict).astype(int)\n",
    "all_data[\"HeatingQC\"] = all_data[\"HeatingQC\"].map(qual_dict).astype(int)\n",
    "all_data[\"KitchenQual\"] = all_data[\"KitchenQual\"].map(qual_dict).astype(int)\n",
    "all_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].map(qual_dict).astype(int)\n",
    "all_data[\"GarageQual\"] = all_data[\"GarageQual\"].map(qual_dict).astype(int)\n",
    "all_data[\"GarageCond\"] = all_data[\"GarageCond\"].map(qual_dict).astype(int)\n",
    "\n",
    "all_data[\"BsmtExposure\"] = all_data[\"BsmtExposure\"].map(\n",
    "        {\"None\": 0, \"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4}).astype(int)\n",
    "\n",
    "bsmt_fin_dict = {\"None\": 0, \"Unf\": 1, \"LwQ\": 2, \"Rec\": 3, \"BLQ\": 4, \"ALQ\": 5, \"GLQ\": 6}\n",
    "all_data[\"BsmtFinType1\"] = all_data[\"BsmtFinType1\"].map(bsmt_fin_dict).astype(int)\n",
    "all_data[\"BsmtFinType2\"] = all_data[\"BsmtFinType2\"].map(bsmt_fin_dict).astype(int)\n",
    "\n",
    "all_data[\"Functional\"] = all_data[\"Functional\"].map(\n",
    "        {\"None\": 0, \"Sal\": 1, \"Sev\": 2, \"Maj2\": 3, \"Maj1\": 4, \n",
    "         \"Mod\": 5, \"Min2\": 6, \"Min1\": 7, \"Typ\": 8}).astype(int)\n",
    "\n",
    "all_data[\"GarageFinish\"] = all_data[\"GarageFinish\"].map(\n",
    "        {\"None\": 0, \"Unf\": 1, \"RFn\": 2, \"Fin\": 3}).astype(int)\n",
    "\n",
    "all_data[\"Fence\"] = all_data[\"Fence\"].map(\n",
    "        {\"None\": 0, \"MnWw\": 1, \"GdWo\": 2, \"MnPrv\": 3, \"GdPrv\": 4}).astype(int)\n",
    "\n",
    "all_data[\"PoolQC\"] = all_data[\"PoolQC\"].map(qual_dict).astype(int)\n",
    "\n",
    "# Most land slopes are gentle; treat the others as \"not gentle\".\n",
    "all_data[\"LandSlope\"] = (all_data[\"LandSlope\"] == \"Gtl\") * 1\n",
    "# IR2 and IR3 don't appear that often, so just make a distinction\n",
    "# between regular and irregular.\n",
    "all_data[\"LotShape\"] = (all_data[\"LotShape\"] == \"Reg\") * 1\n",
    "# Most properties use standard circuit breakers.\n",
    "all_data[\"Electrical\"] = (all_data[\"Electrical\"] == \"SBrkr\") * 1\n",
    "# Most have a paved drive. Treat dirt/gravel and partial pavement\n",
    "# as \"not paved\".\n",
    "all_data[\"PavedDrive\"] = (all_data[\"PavedDrive\"] == \"Y\") * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 272)\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.get_dummies(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:] #prediction data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_size = 0.3\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train, \n",
    "#                                                     ytrain,\n",
    "#                                                     train_size=1-test_size, \n",
    "#                                                     test_size=test_size, \n",
    "#                                                 random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base models\n",
    "\n",
    "The parameters of the base models should be tuned separately.\n",
    "\n",
    "### XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### XGBoost parameters\n",
    "params={'max_depth': 2,\n",
    " 'min_child_weight': 1.9038260686533586,\n",
    " 'eta': 0.1,\n",
    " 'subsample': 0.6005500786487102,\n",
    " 'colsample_bytree': 0.3375793337385239,\n",
    " 'gamma': 0.019079813666906587,\n",
    " 'alpha': 0.07935229891255768,\n",
    " 'lambda': 1.555371731160462,\n",
    " 'objective': 'reg:linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3375793337385239, gamma=0.019079813666906587,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=1.9038260686533586, missing=None,\n",
       "       n_estimators=2200, n_jobs=1, nthread=-1, objective='reg:linear',\n",
       "       random_state=42, reg_alpha=0.07935229891255768,\n",
       "       reg_lambda=1.555371731160462, scale_pos_weight=1, seed=None,\n",
       "       silent=1, subsample=0.6005500786487102)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=params['colsample_bytree'], \n",
    "                             gamma=params['gamma'], \n",
    "                             learning_rate=params['eta'], max_depth=int(round(params['max_depth'])), \n",
    "                             min_child_weight=params['min_child_weight'], n_estimators=2200,\n",
    "                             reg_alpha=params['alpha'], reg_lambda=params['lambda'],\n",
    "                             subsample=params['subsample'], silent=1,\n",
    "                             random_state =42, nthread = -1)\n",
    "\n",
    "model_xgb.fit(train, ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/holy/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.0006, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassocv_alpha = 0.0006\n",
    "model_lasso = linear_model.Lasso(alpha=lassocv_alpha)\n",
    "model_lasso.fit(train, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=30, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgecv_alpha = 30\n",
    "model_ridge = linear_model.Ridge(alpha=ridgecv_alpha)\n",
    "model_ridge.fit(train, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, bagging_seed=9,\n",
       "       boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       feature_fraction=0.2319, feature_fraction_seed=9,\n",
       "       learning_rate=0.05, max_bin=55, max_depth=-1, min_child_samples=20,\n",
       "       min_child_weight=0.001, min_data_in_leaf=6, min_split_gain=0.0,\n",
       "       min_sum_hessian_in_leaf=11, n_estimators=720, n_jobs=-1,\n",
       "       num_leaves=5, objective='regression', random_state=None,\n",
       "       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "       subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb=lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "model_lgb.fit(train, ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/holy/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.010576730829554074, copy_X=True, fit_intercept=True,\n",
       "      l1_ratio=0.11226021096325794, max_iter=1000, normalize=False,\n",
       "      positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elnParams={'l1_ratio': 0.11226021096325794, 'alpha': 0.010576730829554074}\n",
    "\n",
    "model_eln = linear_model.ElasticNet(l1_ratio=elnParams['l1_ratio'],\n",
    "                                   alpha=elnParams[\"alpha\"])\n",
    "\n",
    "model_eln.fit(train, ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup models\n",
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=23)\n",
    "\n",
    "## Parameters for ridge, lasso and elastic net, I just copied from a kernel somewhere.\n",
    "## Should play around with the parameters\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [0.00005, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005,\n",
    "           0.0006, 0.0007, 0.0008]\n",
    "alphas = [0.00005, 0.0001, 0.0003, 0.0005, 0.0007, \n",
    "          0.0009, 0.01]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "ridge = make_pipeline(RobustScaler(), \n",
    "                      linear_model.RidgeCV(alphas = alphas_alt, cv=kfolds))\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(),\n",
    "                      linear_model.LassoCV(max_iter=1e7, alphas = alphas2,\n",
    "                              random_state = 42, cv=kfolds))\n",
    "\n",
    "elasticnet = make_pipeline(RobustScaler(), \n",
    "                           linear_model.ElasticNetCV(max_iter=1e7, alphas=e_alphas, \n",
    "                                        cv=kfolds, l1_ratio=e_l1ratio))\n",
    "\n",
    "lightgbm = make_pipeline(RobustScaler(),\n",
    "                        lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                                      learning_rate=0.05, n_estimators=720,\n",
    "                                      max_bin = 55, bagging_fraction = 0.8,\n",
    "                                      bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                                      feature_fraction_seed=9, bagging_seed=9,\n",
    "                                      min_data_in_leaf =6, \n",
    "                                      min_sum_hessian_in_leaf = 11))\n",
    "\n",
    "xgboost = make_pipeline(RobustScaler(),\n",
    "                        XGBRegressor(learning_rate =0.01, n_estimators=3460, \n",
    "                                     max_depth=3,min_child_weight=0 ,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     objective= 'reg:linear',nthread=4,\n",
    "                                     scale_pos_weight=1,seed=27, \n",
    "                                     reg_alpha=0.00006))\n",
    "\n",
    "\n",
    "#stack\n",
    "stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, \n",
    "                                            xgboost, lightgbm), \n",
    "                               meta_regressor=xgboost,\n",
    "                               use_features_in_secondary=True)\n",
    "\n",
    "#prepare dataframes\n",
    "stackX = np.array(train)\n",
    "stacky = np.array(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_gen_model = stack_gen.fit(stackX, stacky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "eln_preds = model_eln.predict(test)\n",
    "lasso_preds = model_lasso.predict(test)\n",
    "ridge_preds = model_ridge.predict(test)\n",
    "stack_gen_preds = stack_gen_model.predict(test)\n",
    "xgb_preds = model_xgb.predict(test)\n",
    "lgbm_preds = model_lgb.predict(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = (eln_preds+lasso_preds+ridge_preds+stack_gen_preds+xgb_preds+lgbm_preds)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(np.exp(average), index=test_ID, columns=[\"SalePrice\"])\n",
    "pred_df.to_csv('/Users/holy/dsi/module1/averaged_6_models.csv', \n",
    "               header=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({\"features\":train.columns.tolist(),\n",
    "             \"xgb\": list(model_xgb.feature_importances_),\n",
    "            \"lasso\":list(model_lasso.coef_)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>xgb</th>\n",
       "      <th>lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Exterior2nd_AsbShng</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Exterior2nd_AsphShn</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Exterior2nd_Brk Cmn</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Exterior2nd_BrkFace</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Exterior2nd_CBlock</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Exterior2nd_CmentBd</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Exterior2nd_HdBoard</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Exterior2nd_ImStucc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Exterior2nd_MetalSd</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Exterior2nd_Other</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Exterior2nd_Plywood</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Exterior2nd_Stone</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Exterior2nd_Stucco</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Exterior2nd_VinylSd</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Exterior2nd_Wd Sdng</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Exterior2nd_Wd Shng</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                features       xgb  lasso\n",
       "211  Exterior2nd_AsbShng  0.000745   -0.0\n",
       "212  Exterior2nd_AsphShn  0.000000   -0.0\n",
       "213  Exterior2nd_Brk Cmn  0.000372   -0.0\n",
       "214  Exterior2nd_BrkFace  0.000000   -0.0\n",
       "215   Exterior2nd_CBlock  0.000000   -0.0\n",
       "216  Exterior2nd_CmentBd  0.000000    0.0\n",
       "217  Exterior2nd_HdBoard  0.001117   -0.0\n",
       "218  Exterior2nd_ImStucc  0.000000    0.0\n",
       "219  Exterior2nd_MetalSd  0.001117    0.0\n",
       "220    Exterior2nd_Other  0.000000   -0.0\n",
       "221  Exterior2nd_Plywood  0.001862   -0.0\n",
       "222    Exterior2nd_Stone  0.000000    0.0\n",
       "223   Exterior2nd_Stucco  0.000000    0.0\n",
       "224  Exterior2nd_VinylSd  0.000372    0.0\n",
       "225  Exterior2nd_Wd Sdng  0.000372    0.0\n",
       "226  Exterior2nd_Wd Shng  0.000372   -0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance[feature_importance[\"features\"].str.startswith(\"Exterior2nd\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>xgb</th>\n",
       "      <th>lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1stFlrSF_log_sq</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>0.008283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           features       xgb     lasso\n",
       "89  1stFlrSF_log_sq  0.010052  0.008283"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance[feature_importance[\"features\"]=='1stFlrSF_log_sq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 3)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing weights using neural networks\n",
    "This is a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(1,),solver='lbfgs', max_iter=100, activation='identity',\n",
    "                           random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_X_train = np.transpose(np.vstack((y_train_eln, y_train_las, y_train_lgb, \n",
    "                        y_train_rdg, y_train_xgb,stack_gen_train)))\n",
    "\n",
    "mlp_X_test = np.transpose(np.vstack((y_test_eln, y_test_las, y_test_lgb, \n",
    "                        y_test_rdg, y_test_xgb,stack_gen_test)))\n",
    "\n",
    "mlp_X_pred = np.transpose(np.vstack((eln_prediction, las_prediction, lgb_prediction, \n",
    "                        rdg_prediction, xgb_prediction,stack_gen_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(mlp_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mlp = mlp.predict(mlp_X_train)\n",
    "y_test_mlp = mlp.predict(mlp_X_test)\n",
    "mlp_prediction = mlp.predict(mlp_X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(np.exp(mlp_prediction), index=test_ID, columns=[\"SalePrice\"])\n",
    "pred_df.to_csv('/Users/holy/dsi/module1/weighted_ensemble_neural_network.csv', \n",
    "               header=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
